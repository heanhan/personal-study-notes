在互联网应用中，我们通常会遇到一些利用多线程或者多进程的场景，例如：

-   支付下单之后触发一次邮件发送操作；
-   定期备份日志、定期备份数据库；
-   分布式任务计算；
-   Tomcat 内部采用多线程，上百个客户端访问同一个 Web 应用，Tomcat 接入后，就把后续的处理扔给一个新的线程来处理，这个新的线程最后调用我们的 servlet 程序，比如 doGet 或者 doPost 方法。

这些都是在利用线程或者进程技术来提升计算速度，完成一些复杂的业务场景。可以看出，合理地利用多线程或者多进程可以帮助我们对当前程序进行优化，但如果运用地不恰当，也有可能会“翻车”，例如：

-   单台机器部署了太多的应用，导致内存溢出；
-   在配置线程池的时候没有关注CPU的核心数，导致线程池的效率无法合理利用。

要想避免此类问题，我们需要能够深入到操作系统层面，深入理解进程和线程。

### 怎么理解进程和线程？

首先说说我自己对于进程和线程两个概念的理解，**进程是CPU的一个基本资源分配单位，线程是任务执行的基本单元。**

其实在早期的操作系统中，是没有“线程”概念的，大部分都是直接以“进程”作为任务执行的基本单元，那进程在运行过程中所产生的数据都被存在哪里呢？这里我们就需要了解下 PCB 这个概念了。

PCB 其实是一种描述进程的数据结构，它是专门用于存储每个进程在运行过程中所产生和需要的内存数据。

我们在前边的章节中介绍了寄存器的运作原理，当 CPU 发生时间片中断的时候，进程会发生上下文切换，此时需要将老进程执行过程中所使用的寄存器都存储到 PCB 当中，等后续再次恢复上下文的时候使用，整体情况如下图所示：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7a91c3efb71f4b6fb44e200c135fb03a~tplv-k3u1fbpfcp-watermark.image?)


在 PCB 的内部存在以下信息：进程的创建者标识，进程在执行程序的时候需要用到的**寄存器信息** **、** **栈指针** **、** **进程运行中所产生的内存数据。**

在操作系统底层，可能会同时运作着许多个进程，每个进程的数据之所以能做到互相独立，关键点之一就是有了 PCB 的存在。面对如此之多的进程，操作系统又是如何存放它们的呢？

由于每个进程都有各自的状态，有些可能是出于睡眠状态，有些可能是出于阻塞状态，还有的会处于空闲或者是正在执行状态，为了能够实现对它们的分类管理以及快速定位，操作系统设计了一个**索引链表**对它进行管理，其结构如下图所示：


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/25f8f5151342414d86aef259f2b72ca5~tplv-k3u1fbpfcp-watermark.image?)

操作系统底层按照不同的进程状态设计了不同的队列，每个队列的首部都会有一个指针管理，这些队列在内存中采用链表的方式去组织，合理地利用了内存的内存空间。

其实每个进程都是存在于互相独立的内存空间中，就如同下图所示：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/662eccb1a5e04f9f9e7e8a9cfc75f969~tplv-k3u1fbpfcp-watermark.image?)

在采用多进程协作开发的过程中，程序员们发现这种设计存在一定的弊端，因为在进程在进行相互协作的过程中如果需要进行通信的话，其成本是比较大的，需要分配额外的内存资源，建立 **PCB**，回收资源等，其切换的流程图如下所示：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce93b311c68246a3ae556b684084d1f6~tplv-k3u1fbpfcp-watermark.image?)

那么，既然进程的切换开销比较大，能否设计一种技术去降低这种切换和互相通信所带来的巨大开销？于是人们开始提出一种设想，渐渐地，一种轻量级的进程技术--线程便诞生了。


### 线程：更小的“进程”

线程其实可以看作是一个更小的“进程”，来看下边这张图，你或许就会对线程有更加深刻的认识了。下边这张图解释了同一个进程内部运行的两个线程的内存布局。


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4180d998d8684bf5a30b8f25d6b368c1~tplv-k3u1fbpfcp-watermark.image?)


当发生线程上下文切换的时候，正在执行的线程会将运行程序时所产生的信息保存在一个叫做 **TCB** 的地方。这个 TCB 可以类比为 PCB 的迷你版本，也就是上图中粉色块部分。

各个 TCB 中都有着专属的**程序计数器** **、** **寄存器** **、** **堆栈记录**，它们各自的属性都是独立开来的，但是它们实际上都是在占用着进程所提供的资源，这一点我们称之为**资源共享**。同一个进程内的线程具有资源共享性，也就意味着同一个进程中的变量会被多个线程并发访问，这也正是并发编程中经常会被程序员们所提及的**线程安全**问题。

了解到这里，你应该对线程和进程的基本内部组成有了一定的了解了吧，正因为它们的内部组成不同，上下文切换的开销不同，所以在许多并发编程领域中，会优先采用多线程的思路去实现。

**但这里很容易又让初学者们进入到一个新的误区** **：线程创建得越多，计算的性能就会越高？** 要搞懂这一点，我们需要深入线程的内部模型。

### 线程模型有哪几类？

#### **用户线程**

这种线程只存在于用户态，操作系统内核对它的存在是无感知的。用户态线程的调度策略统一交由程序编写的线程库函数来进行维护和管理，它所拥有的内存资源均是来自于它所处在的进程中，而这个进程对于操作系统来说是可以感知的，但是对于进程内部的各个用户态线程而言，操作系统就无法了解到其内部的具体存储信息了。

为了让大家对于用户线程的结构有更好的理解，我整理了一张图，如下所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0db39b280e234e73941d9147bbbd2a65~tplv-k3u1fbpfcp-zoom-1.image)

用户线程中的 TCB 存储在了程序所编写的库中，每个进程都会有一个集合用于存储自己的 TCB 信息，这些 TCB 集合信息中记录了每个线程当前执行的程序指令地址，线程的状态等等。由于用户线程在设计之初就没有考虑过需要和内核态打交道，所以它的创建、同步、终止、调度都是由一个库函数去进行管理的，包括它的调度策略也是可以自定义扩展。

在早期的一些操作系统中用户线程还是有应用场景的，尤其是在一些主推支持进程模型的操作系统中，如果有同学对这方面感兴趣的话，可以去了解下 Solaris 这款操作系统。

看到这，你可能会感觉到用户线程设计的轻巧性，用户态线程之间的切换完全在用户态进行管理了，是不是多并发场景下的性能就一定能提升了许多？其实用户态线程依然存在些许问题：

**1.如果进程被操作系统设置为等待状态，那么这个进程内部的各个线程都会处于等待状态。**

假设进程中的一个线程发起了读取磁盘信息的系统调用，随之会让操作系统认为是整个进程发起了系统调用，此时 CPU 会收到调度指令，认为这个进程当前处于等待 io 响应的状态，于是将时间片先转给其他**进程**执行。那么就会造成这个进程中的其他线程都处于等待状态。

**2.当一个线程开始运行之后，除非它主动交出CPU的使用权，否则它所在进程中的其他线程就会无法运行。**

**3.由于时间片资源分配是给进程的，所以运作在进程上的各个线程所拥有的时间片会比较少，因此当多线程执行的时候就会比较慢。**

#### 内核线程

这类线程的资源和调度都交给了操作系统进行管理，它本身的调度和资源协调都是由操作系统管控的。其内部的构造如下图所示：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a50ad424d824423869a75f5361bc9e9~tplv-k3u1fbpfcp-watermark.image?)


**内核线程模型中，会将TCB存放在内核空间中，这样在做线程的创建** **、** **终止** **、** **切换就都需要经过一轮系统调用的方式来执行了，因此性能开销会稍微大一些，但是这样的好处在于操作系统的内核可以对该线程“有感知”，能够合理以线程作为基本维度去考虑时间片的划分。**

在早期的 Windows NT 和 Windows 2000/XP 操作系统中就有应用过这类内核线程的设计。

#### 轻量级进程

轻量级进程简称 LWP（LightWeight Process），这是一种结合了用户态线程和内核态线程所设计出的一种模型。大致可以理解为，用户态的线程通过一个“转发器”，映射到内核态中的一个内核线程，而这个转发器的角色就是LWP，其基本结构如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a51534d36114bfb9e1ce80a6694db8c~tplv-k3u1fbpfcp-zoom-1.image)

你可以将 LWP 理解为是用户线程与内核线程直接进行通信的一个“中间人”，LWP 的一端连接着用户态线程，一段关联着内核态线程，如果内核态线程发生了阻塞，那么另一端的用户态线程也会阻塞。

LWP 的设计为了让用户态中创建的线程在内核态中会有一个内核线程与之映射，实现对时间片的抢占效果。在 Linux 操作系统中，通常用户态线程和内核态线程会呈现 n:m 的比例，这种多对多的关系，减少了内核线程，同时也保证了多核心并发，其基本结构如下所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b12888a1df9a4f6b93396e211d33832e~tplv-k3u1fbpfcp-zoom-1.image)

在 Linux 2.4 之后的操作系统中，出现了 upcalls 机制，upcalls 可以理解为是用户态线程发出的一个信号通知，期待让内核态线程随时执行用户态所编写的程序，对 upcalls 感兴趣的同学可以去阅读下官方的[内核文档](https://lkml.iu.edu/hypermail/linux/kernel/9809.3/0922.html)介绍。


### 课后小结

在本章节中我们重点介绍了线程和进程的一些基本概念和底层设计，以及在操作系统内部是如何管理这些复杂的线程与进程的。最后让我们总结下本章节的主要核心知识点：

-   进程和线程的理解，PCB 和 TCB 的认识。
-   线程常见的几种模型有哪些，各自有什么特点。

### 课后思考

**上节课答疑**

上一章节的末尾处我们留下了关于虚假唤醒这个疑惑点给大家讨论，这里我说下自己的一些思考：

来看下下边这段代码：


```java
void test1(){
    if(!isSafe){
      obj.wait(); //code1
    }
    //下边是一系列的业务逻辑
    ...
}

void test2(){
    while(!isSafe){
      obj.wait(); //code2
    }
    //下边是一系列的业务逻辑
    ...
}
```

先来看 test1 函数，在 code1 处被唤醒之后，可能那一瞬间 isSafe 依然为 false，而此时程序却执行到了后边流程的代码，从而可能会存在一些安全隐患问题，所以这类情况我们一般称之为“虚假唤醒”。为了避免这类问题，通常我们会在“唤醒”之后再做一次判断，例如 test2 函数的写法。这一点在 JDK 的很多框架源代码底层都有所体现，例如：

```java
synchronized (queue) {
    try {
        Thread.sleep(1000);
        //有可能这里被再次唤醒的时候已经不满足条件了，所以需要注意
        while (queue.size() != 0) {
            queue.wait();
        }
        queue.add(++i);
        System.out.println("【生产者】data: " + i);
        queue.notify();
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
```


所以在了解了“虚假唤醒”之后，大家以后在写代码的过程中就尽量避开这类问题吧。

**本章节思考**

线程在进行上下文切换的过程中可能会有哪些问题呢，欢迎大家在评论区进行讨论。