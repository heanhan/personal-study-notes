上一篇文章中我们通过对 CPU 的底层认识，了解了CPU在运行程序过程中的一些细节，同时也看到了并发执行程序的时候可能会存在的问题，那么计算机底层是否有什么方式去避免这些问题呢？其实发明操作系统的人很早就已经给出了一套解决方案，其中最为人们熟知的就是**管程和信号量**了。

### **临界区**

在开始介绍信号量和管程之前，我们需要先有一定的铺垫，先来看下边这么一段代码案例：

```java
public class IncrDemo {
    static int i=0;

    public void incr(){
        i++;
    }
}
```

这段程序非常简单，就是对 i 进行自增的操作，在单线程下这个程序执行是正常的，但是多线程的场景下就可能会出现数据错乱的问题了。当多个线程同时执行 incr 方法的时候，对于 i 的自增操作就是一个对于**临界区**的访问操作。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/84061d4d5f8445b1896cc42f62765b65~tplv-k3u1fbpfcp-watermark.image?)

临界区是操作系统底层的一项专业术语，通常用于描述共享资源块。当某一时刻同时有多个进程或者线程访问同一临界区的时候，每次只能允许有一个线程访问成功，其他线程则需要进入等待状态。为了实现这种效果，操作系统需要确保对于临界区的资源每次访问都只能有一个请求抵达，于是乎便有了**信号量**这个概念的出现。


### **信号量**

#### 什么是信号量

信号量其实是一种设计思想，它的本质可以理解为是一个整形的数字(sem)，对于这个数字的访问，在具体实现上只提供两个原子操作，分别是：

-   P()：如果执行sem-1之前，sem已经0，则进入等待状态，否则就只是正常扣减操作。

<!---->

-   V()：如果执行sem+1之前，sem已经0，则执行完sem+1之后同时会唤醒一个等待的P，否则就只是正常的加1操作。

信号量的操作之所以具备原子性，这是和它的底层实现有关。操作系统的底层提供了一对原语来对其进行操作，所谓的原语其实是一种非常特别的程序段，这类程序要么一气呵成，要么不可被中断。

看到这里，没有了解过信号量的同学可能会有些疑惑，这是个啥玩意儿？别急，我们通过一张图来认识下。

下图中模拟了当一个请求访问到某块临界区的时候，触发到预先在程序中设定好的P操作，触发sem-1操作，从而使得sem=0。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d7949a6a3811424c95767aa8bd244d79~tplv-k3u1fbpfcp-watermark.image?)

接下来，当有多个请求抵达临界区的时候，它们都会陆续触发到P操作，但是此时 sem 值已经变为 0 了，于是乎后续的请求就会被放置到一条等待队列中。



![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0260d934bb6b48dba2fac426c9437125~tplv-k3u1fbpfcp-watermark.image?)

随着之前在临界区的访问处理结束之后，就会触发一次 V 操作，将 sem 进行加 1，然后会从等待队列的队头通知一个之前的处于等待状态的请求，让其进入临界区，接下来的请求请以此类推。

怎么样，是不是感觉这种设计思路在高级语言中似曾相识。其实很多高级语言的设计都是来源自操作系统当中。

可能会有部分同学有疑问，这无非就是对一个数值的加或者减嘛，为什么要叫做P和V操作呢？关于这块我之前在学习的时候也有疑惑，后来才得知，发明信号量机制的工程师是荷兰人，P 和 V 分表都是荷兰用语，代表的意思是V **verhoog** 增加，**P prolaag** 减少。

#### 信号量在不同场景中的应用

上边的例子中，我们已经对信号量的基本模型有了一定的了解，下边我们来通过几个案例了解下信号量在不同场景中的使用。

-   **实现多进程任务执行的先后顺序**

A 进程的 method_3 需要在 B 进程执行 method_2 之后才运行，那么这个时候运用信号量进行实现的话就会非常简单，基本思路如下图所示：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8bdcee56112e483cb837bd46a0a5789a~tplv-k3u1fbpfcp-watermark.image?)

在执行 method1 和 method2 之前，先将 sem 设置为 0，于是当 A 进程在想执行 method_3 之前，因为遇到了 sem=0 的情况，于是在调用P的时候处于堵塞状态。而此时需要借助 B 进程去发起 V 操作，才能让 A 线程继续执行，这样就能保证 A 进程每次执行 method_3 之前都是有 B 进程执行过一次 method_2 操作。

-   **实现多进程间任务的前驱关系**

进程 P1 中存在函数 S1，进程 P2 中存在函数 S2，进程 P3 中存在函数 S3，后续的进程 P4、P5、P6以此类推。现在需要确保各个进程中函数的执行顺序为 S1->S2->S3，S4->S5，S6，其中 S3 和 S4 之间没有优先级关系，S5，S6之间也是没有优先级关系，这种情况下其实也是可以借助信号量机制去进行实现。


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3aad6a689cae466090aa53bc5ae3fd6c~tplv-k3u1fbpfcp-watermark.image?)

-   **通过信号量来实现访问次数限制**

对于某项资源访问，它只能同时允许有 3 个进程读取，当进程数量超过 3 个，则需要进入等待。这类场景非常好理解，只需要将 sem 设置为 3 即可。

在出现了信号量机制之后，虽然能够解决一部分简单的并发问题，但是在使用方式上依然是存在一些缺陷，于是部分聪明的程序员对信号量做了一层**可读性更强的代码封装**，这个封装的结果就是我们下边要介绍的**管程**。

### 管程

管程 英文名为**monitor**，翻译过来就是指监视器的意思，对于管程的理解，大致可以认为是基于信号量的基础做了一层封装，专门用于访问一些共享变量的函数，让调用方使用起来更加简单和清晰，它的作用是一次只允许有一个线程访问临界区，如果同时有多个访问，则将多余的访问挂起。

**这里需要注意的是，信号量的应用主要是基于操作系统层面中，而管程的提出** **，** **则是用在了语言的场景中，它主要是专门针对语言中的并发场景而设计的，从而简化了一些语言层面的实现逻辑。**

例如Java内部对于并发模块的实现 wait()、notify()、notifyAll() 这些函数就是采用了管程技术来控制的。

看到这里，可能依然会有些同学对于管程的运作原理感到模糊，下边我们一起探讨管程的内部组成和运作原理，相信看完之后，你便会有所解惑。

#### **管程的组成**

-   一把锁

<!---->

-   0或者多个条件变量

**一把锁：** 管程为了保证对于共享资源的访问一次只能有一个进程，所以引入了锁的机制，没有抢到锁的进程则需要进入到**锁的等待队列进行等待。**

**0或者多个条件变量：** 当进程获取到了锁的请求进入到临界区之后，有可能还需要做多个条件的判断，如果没有满足其中的某一条条件则需要进入到**条件队列**（条件队列位于临界区外）中，若后续条件满足，则由其他进程进行唤醒。

因此它的结构可以用下图来描述：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/63b29c9e97c5420b8328aa795326193f~tplv-k3u1fbpfcp-watermark.image?)

现在我们对管程的执行逻辑有了一个初步的认识，再来看看指令级别该如何去设计和实现它。
上边我们说了，管程的内部需要有一把锁，因此对应的锁可以设计一套API去进行定义:

```java
Lock::Acquire() //等待锁可用，然后抢占
Lock::Release() //释放锁，唤醒等待队列中的线程
Wait() //释放当前锁，进入睡眠状态，
Signal() //当某个条件满足的时候，就会唤醒等待队列中线程
```
关于不同条件的等待队列部分，我将其核心的逻辑做了些许抽象，实现如下：

```C++
//设计一个条件类
Class Condition {
  //记录有多少个线程等待该条件
  int numWaiting=0;
  //存储等待该条件的队列
  WaitQueue q;
}

//当有线程调用wait函数的时候，该线程会被挂起在该条件队列中
Condition::Wait(lock){
  numWaiting++;
  //将当前线程放入到条件队列中
  add currentThread t to q;
  //释放锁
  release(lock);
  //调度一个处于就绪状态的线程执行，这里相当于发生了线程的上下文切换
  schedule();
  //重新获取锁
  require(lock);
}

//从等待队列中移除一个处于挂起状态的线程t，让其继续执行
Condition:Signal(){
  if(numWaiting >0){
  //从条件队列中移除线程
  Remove one thread t from q;
  //唤醒一个处于睡眠状态的进程，如果此时没有线程处于条件队列中，这里就会堵塞。
  wakeup(t);
  numWaiting---;
  }
}

```
从上边的这段简化版代码中，我只是基于对管程的理解，设计了一个简单的基本伪代码，大致思路为：每次进行抢锁的时候都只能运行一个线程成功，如果抢夺到锁的线程希望主动释放锁，那么就需要主动调用 wait 方法。如果希望唤醒那些调用了 wait 方法的线程，就需要调用 signal 方法。

不过这里有个细节需要注意下：**为什么wait操作中** **，** **要先执行release 再执行require操作？**

这是因为进入睡眠状态前，线程必须要将它所拥有的锁进行释放，否则会一直处于死锁状态。当线程被唤醒后，程序又会重新回到 schedule 代码后边一条指令进行执行，于是这个时候就有需要重新尝试获取锁。

上边我们介绍了如何给予代码实现去设计一个基本的管程模型，但你发现没？当 Condition 调用了 signal() 函数的时候，会唤醒条件队列中的一个挂起线程，那么就会产生同时有两个线程访问到了临界区的共享资源，一个是当前触发 signal 函数的线程，一个是刚从挂起状态被唤醒的线程，这种情况下该如何处理呢？

#### Hansen， Hoare， Mesa模型

其实上边所说的问题在很早之前就已经有程序员们注意到了，当时为了解决这两种问题，业界提出了三种管程的模型，它们分别是Hansen模型，Hoare模型，Mesa模型，为了方便下边描述，我们暂时称呼被挂起的线程为 A，调用 signal 的线程为 B。

-   **Hoare 模型**

这种模型的核心关注点是急迫性的，**它会让A立即执行，而当前调用signal方法的B处于睡眠状态，在等待的A执行之后才继续让B执行。** 因此在这种模型下去设计管程，就需要程序员养成一个将 signal 操作放到函数最后一步才去执行的习惯。

-   **Hansen 模型**

这类模型不强调立马释放cpu的占有权利，**会等当前B完全执行完毕之后，才允许让被唤醒的A继续执行。** 在这种模型中，程序员可以不用担心 signal 操作之后是否会有等待的情况发生，更加灵活。

这两种模型其实各有各的考虑出发点，Hoare的表现更为急迫性，而 Hansen 则是更加考虑灵活性，并不能直接评判两类模型谁更好，只不过在具体实现层面来说，Hansen 模型要比 Hoare 模型更加容易一些。

关于两类模型的执行原理图如下所示：

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1816003d7fc841cb8fd0bba56c78b03d~tplv-k3u1fbpfcp-watermark.image?)

这两类模型都有个特点，就是线程被重新唤醒之后就能继续执行，因为它们被唤醒之后都是可以直接存在于临界区，只不过它们都只允许单个线程访问临界区中的资源。但是还有一种模型和这个不太一样，那就是 MESA 模型。

-   **Mesa模型**

在 Mesa 模型中，B 在执行了 signal 之后，不需要担心 A 的任何事情，B 可以继续正常执行。而 A 会被重新放入到等待队列中去参与抢占的行为，这一点和 Hansen、Hoare 是不一样的，被重新唤醒的线程会被移出临界区。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1e3a2a2b92ed49e4b0f02635b0207bce~tplv-k3u1fbpfcp-watermark.image?)

Mesa 模型也是 Java 语言所采用的管程模型，在 JDK 的 synchronized 中，就是基于 Mesa 管程模型去进行了封装，对外主要提供了 wait、notify、notifyAll三个函数，关于它们的进一步深入了解，我会在后续的章节中带大家专门深入探索。

#### 管程模型实现生产者消费者

有了上边基本的设计思路，我们来看看如何将上边所设计的管程的 API 应用于生产者消费者模型中，下边我给出了些自己的设计思路：

```java
//设计了一个buffer对象，内部管理了一把Lock和两个Condition条件以及共享资源count和q
Class Buffer {
 Lock lock;
 int count=0;
 Queue q;
 Condition notFull,Condition notEmpty;
}

//往队列放入元素
Buffer::Deposit(c){
  //获取锁，进入临界区
  lock -> Acquire();
  //当队列的体积满足某个条件的时候便将当前线程刮起到等待队列中
  //此时count==n的意思是当队列的容积达到了上限1，这个就是当前的需要被判断是否满足的条件
  while(count == 1){
     //条件满足，挂起，同时底层会放弃lock
     notFull.Wait(&lock);
  }
  //这里可能是条件未满足，或者是线程重新从睡眠状态被唤醒的情况。将c放入到队列中
  add c to the q;
  //队列个数加1
  count++;
  notEmpty.Signal();
  //释放锁
  lock -> Release();
}

Buffer::Remove(){
  //获取锁，进入临界区
  lock -> Acquire();
  while(count==0){
   //当队列中没有元素了，此时消费线程就需要被挂起到等待队列中，同时底层会放弃lock
    notEmpty.Wait(&lock);
  }
  //这里可能是条件未满足，或者是线程重新从睡眠状态被唤醒的情况。从q中继续提取元素处理
  remove c from the q;
  count--;
  //消费完毕后，通知生产者往q中放入下一个元素
  notFull.Signal();
  //释放锁
  lock -> Release();
} 
```
配合着代码的注释解释，我们大概了解了对如何基于管程去操控一些多线程间访问的机制，这些代码采用了一些伪代码的思路去进行实现，希望能对大家得理解有所帮助。

### 课后小结

本章节中我们重点介绍了操作系统内部是关于临界区的一些访问机制，例如通过信号量机制实现，同时也介绍了更加高级的一些技巧，管程模型。在了解管程模型的过程中我们认识到了关于管程出现过的三种典型设计，以及它们之间的微妙差异性。

最后是本章节的知识点归纳，希望大家可以下去深入消化一下：

-   临界区的基本概念；
-   信号量是什么；
-   信号量在操作系统中的使用案例；
-   管程是什么；
-   如何通过代码设计管程；
-   管程的几种设计模型比对；
-   基于管程去实现一个简单的生产者消费者模型。

### 课后思考

**上节课答疑**

在上一章节的末尾处，我留下了一道思考题，在 CPU 读取内存数据到寄存器的过程中需要考虑哪些问题？下边我给出一些自己的思考：

其实内存的计算速度和寄存器的计算速度差别也不是一星半点，所以 CPU 为了弥补这类速度差便加入了多级缓存，通过硬件设备的技术来缓解这类速度差异性，如果寄存器查询不到数据，便会到 L1->L2->L3 级缓存中进行查询，通常情况下，计算器所需要的数据都能在三级缓存中查询到。

虽然三级缓存的出现提升了寄存器加载数据的便捷性，但是由于也引入了“缓存一致性”的问题，

通常单个CPU可能会存在有多核心的情况，这类情况下，多个核心使用的L3缓存会是共享的状态。但是随着科技的发展，也有部分的电路主板开始支持了多CPU的架构，而这类情况下，不同的CPU之间的L3级缓存就是各自独立存在的了。

下边这张图是一个双核CPU内部的结构图：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/92384475351b4be1adf2cc6f051c5e29~tplv-k3u1fbpfcp-watermark.image?)

假设有这么一段程序：

```java
int count = 0；
count = count +1；
```

某一时刻同时有两个不同的线程 t1、t2 分别从不同的 CPU 将其加载到自己的存储单元内做运算，count=count+1 处理的时候就会出现一个问题，不同的 CPU 读取到的 count 都是 1，互相之间互不可见，这样就会导致一个问题，CPU 对 count 实际上做了两次从 count+1 操作，最终结果的结果确是 1。这种不一致的现象我们通常称之为缓存不一致性问题。

解决方案如下:

1.  **总线加锁方案**

对总线进行加锁处理，当有两个及以上的 CPU 需要通过 IO 总线去访问内存同一个地址数据的时候进行加锁处理，一次只允许一个 CPU 将数据加载到寄存器当中进行计算，然后将其写回到内存设备之后再释放锁，让另一个 CPU 去进行计算工作。

弊端：性能过低，因为 IO 总线上边除了内存设备在访问之外还有其他的硬件设备也在进行访问，会出现堵塞状态。

2.  **缓存一致性协议方案**

除了上边提及的 IO 总线加锁方案之外，采用缓存一致性协议也可以实现相关的优化处理。

这里我们列举最常见的缓存一致性协议 MESI：

-   M 被修改（Modified)
-   E 独享的（Exclusive)
-   S 共享的（Shared)
-   I 无效的（Invalid）

这里我们需要了解几个概念。

 **缓存行（cache line）是什么** **？**

 cache line 是缓存里面的最小单位，根据操作系统一般是 32byte 或 64byte。

 **总线嗅探机制和 MESI 协议**

 要解决缓存一致性问题，首先要解决的是多个 CPU 之间的数据传播问题。

  **总线嗅探（Bus Snooping）** ：最常见的一种解决多核 CPU 数据广播问题的方案。本质上就是把所有的读写请求都通过总线(Bus) 广播给所有的 CPU 核心，然后让各个核心去“嗅探”这些请求，再根据本地的情况进行响应。



**MESI 协议**：基于总线嗅探机制的缓存一致性协议，MESI 协议也是在 Pentium 时代被引入到 Intel CPU。


**MESI 协议**

Modified：意味着当前 CPU 的缓存行数据发生了修改，和内存的数据不一致，此时以 CPU 中的缓存行数据为准（其他 CPU 内部的缓存行不准确）（回写数据阶段，处于 M 状态，此时其他 CPU 通过嗅探机制会监听到此信号，此时其他 CPU 的指定缓存行是处于无效状态 I ）

Exclusive：只有当前 CPU 的缓存行占有数据，其他 CPU 没有读取数据，当前缓存行的数据和 CPU 中的数据是一致的。（此时该 CPU 也会去监听 bus 总线上对于该变量值的改动，也可以称之为总线嗅探机制）

Shared：当前 CPU 和其他 CPU 中的缓存行数据都是一致的，并且也和内存中的数据保持一致。（当多个 CPU 读取同一个变量到寄存器中进行计算的时候，变量就会变成该状态）


Invalid：即当前 CPU 的缓存假若失效了，那么此时应该重新从内存中获取数据。而且每次失效都是整个缓存行失效。

虽然上述的 MESI 协议看似没有问题，但是在某些情况下依然是会有出现失效的情况，下边我列举一些采用缓存一致性导致失效的场景：

1.  缓存的数据体积大于一个缓存行的时候，需要加总线锁。一个数据横跨多个缓存行。
2.  CPU 不支持缓存一致性问题，不过目前大部分主流的CPU都支持缓存一致性。

**本章节思考**

在了解了管程的三种实现模型之后，我们来思考下在基于Mesa模型实现下，Java线程可能会存在虚假唤醒的情况，我们该如何解决这种问题呢？

欢迎大家在底下评论区进行留言讨论，我会在下一章节中给出自己的思考。















