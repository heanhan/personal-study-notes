相信大家在实际工作中，或多或少都使用过日志这种组件，通常我们会用它来记录一些程序执行过程中的数据信息，例如下边这个代码案例：

```
void payNotify(PayNotifyVO param){
    try {
        log.info("payNotify begin,param is {}",param);
        //执行业务逻辑 ....
        log.info("payNofity success,param is {}",param);
    } catch (Exception e){
        log.error("payNotify end,param is {},error is ",param,e);
    }
}
```

假设说这段支付回调的代码哪天出现了异常，我们也可以通过翻看日志记录去快去定位和解决问题。在早期的 JDK 版本中，如果我们希望实现一些日志记录的功能，就只能单纯地依靠System.*out*.println(...),System.*err*.println(...),e.printStackTrace() 去实现。

其实，这样实现的效果并不理想，既不能支持定制化，也不能将信息记录到一份文件中，一旦 Java 进程重启，所有的异常信息就会丢失，而且日志的粒度也不够细致化。

后来随着技术的不断演进，Log4j 这款日志开始面向大众，这款日志的底层设计思想，其实是对 Java 后期的日志组件发展有着长远影响的。它定义的 Logger、Appender、Level 等概念如今已经被广泛使用，后期的 Logback 和 Log4j2 在原先的 Log4j 基础上做了一些改良，开始渐渐被大家所熟知。

Slf4j 也是现在主流的日志门面框架，使用 Slf4j，可以很灵活地使用占位符进行参数占位，简化代码，拥有更好的可读性。

Logback 是 Slf4j 的原生实现框架，同样也是出自 Log4j 一个人之手，但拥有比 log4j 更多的优点、特性和更做强的性能，现在基本都用来代替 log4j 成为主流。

现在我们大概了解了 Java 体系下的各款日志组件的发展路程，那么这些日志组件在设计时，有哪些和并发编程相关的技术点可以让我们学习的嘛？答案是有的，下边让我们来深入了解下，这些组件底层实现过程中都可能会遇到怎样的问题。

## 日志框架的底层都是如何设计的？

如果你有了解过日志框架的话，就会发现，大多数的日志框架底层都会被划分为这三种角色：

-   Logger：日志记录器，负责收集处理日志记录，可以有选择的启动和禁用日志的输出。

<!---->

-   Appender：日志输出目的地，负责日志的输出，一个输出源就叫一个 Appender，appender 的类别有：Console（控制台）File（文件）JDBC、JMS等，logger 可以通过方法logger.addAppender(appender)；配置多个 appender，对 logger 来说，每个有效的日志请求结果都将输出到 logger 本身以及父 logger 的 appender 上。

<!---->

-   Layout：日志格式化，负责对输出的日志格式化。

通常这三者直接的关系是：Logger 可以对应多个 appender，一个 appender 只能对应一个 layout。

### 同步打印记录

这里面的 Appender 就是实现日志内容持久化记录到日志文件中的主要核心。

如果你有阅读过一些日志组件的底层实现，就可以发现日志打印的记录底层是有做加锁处理的，例如 logback 日志的底层实现源代码，在 ch.qos.logback.core.OutputStreamAppender#writeBytes 中的实现如下所示：

```
private void writeBytes(byte[] byteArray) throws IOException {
    if(byteArray == null || byteArray.length == 0)
        return;
    
    lock.lock();
    try {
        this.outputStream.write(byteArray);
        if (immediateFlush) {
            this.outputStream.flush();
        }
    } finally {
        lock.unlock();
    }
}
```

在将程序的轨迹信息记录到日志文件时，需要加入一把 ReentrantLock 去防止同时有多个线程去操作日志文件的写入操作。

看到这里，可能有的人会觉得，这种同步写入日志记录的操作涉及到加锁解锁，过程会比较慢，那么是否可以采用异步的思路来实现日志打印功能呢？

其实是有的，下边让我们来看看如何实现异步打印的功能。

### 异步打印记录

这里我们以 logback 组件的实现来进行介绍。在 LogBack 组件中，有一个叫做 AsyncAppender 的异步写入类，在这个类的底层中有一个叫做 ch.qos.logback.core.AsyncAppenderBase 的类，这个类实现了异步打印日志的逻辑，下边是底层的部分源代码逻辑：

```java
private void put(E eventObject) {
    if (neverBlock) {
        blockingQueue.offer(eventObject);
    } else {
        putUninterruptibly(eventObject);
    }
}

private void putUninterruptibly(E eventObject) {
    boolean interrupted = false;
    try {
        while (true) {
            try {
                //不断尝试，意味着如果队列满了的话，这里会一直阻塞主线程
                blockingQueue.put(eventObject);
                break;
            } catch (InterruptedException e) {
                interrupted = true;
            }
        }
    } finally {
        //如果出现了异常，会中断当前线程
        if (interrupted) {
            Thread.currentThread().interrupt();
        }
    }
}
```

从上边的代码中我们可以看到，日志内容会被放入到一个阻塞队列中，接着会有一个叫做 Worker 的线程专门从这个队列中取出元素去进行处理。具体的处理步骤如下所示：

```
class Worker extends Thread {

    public void run() {
        AsyncAppenderBase<E> parent = AsyncAppenderBase.this;
        AppenderAttachableImpl<E> aai = parent.aai;

        // 应用在启动的时候，这里就为true了
        while (parent.isStarted()) {
            try {
                //不断地轮询从阻塞队列中获取日志信息，然后将它打印出来
                E e = parent.blockingQueue.take();
                aai.appendLoopOnAppenders(e);
            } catch (InterruptedException ie) {
                break;
            }
        }

        addInfo("Worker thread will flush remaining events before exiting. ");

        for (E e : parent.blockingQueue) {
            aai.appendLoopOnAppenders(e);
            parent.blockingQueue.remove(e);
        }

        aai.detachAndStopAllAppenders();
    }
}
```

在很多框架组件中，都有见过这个 Worker 线程的设计类似的影子，先将数据缓存在队列 **（底层使用的是 java.util.concurrent.ArrayBlockingQueue）** 中，然后会有个线程去异步处理它。这样既能提升日志记录的效率，也可以解决在写入日志时候的并发问题。但是采用异步写入时也会存在一些问题点，例如：

-   记录异步日志撑爆内存或者卡顿

由于需要被写入的记录是放入到一条内存队列中，所以一旦队列的消费端出现了卡顿情况，这条队列的体积就会不断膨胀，从而撑爆内存空间。

-   记录异步日志出现阻塞

底层采用的是阻塞队列，在写入日志的时候，会先将数据放入到队列中，如果队列已经满了，则会进入到等待的逻辑，这一步会导致主线程的阻塞。这一点可以通过阅读 ArrayBlockingQueue 的底层源代码了解到。下边是 ArrayBlockingQueue 在执行 offer 方法的时候，底层实现的逻辑：


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/735186d4044c4221adc7b2af5f857e40~tplv-k3u1fbpfcp-watermark.image?)

现在我们大概了解了日志组件底层的两种实现模式：同步记录和异步记录，其实在了解清楚了它的底层原理之后，我们可以结合这些日志组件做些二次开发。例如我们前边的客户层中介绍的基于重写 logback 组件中的 ClassicConverter 类，来实现自定义的日志打印前缀内容。代码的实现内容如下：

```
package dubbo.utils;

import ch.qos.logback.classic.pattern.ClassicConverter;
import ch.qos.logback.classic.spi.ILoggingEvent;
import dubbo.constants.RequestContentConstants;
import dubbo.context.CommonRequest;
import dubbo.context.CommonRequestContext;

/**
*  @Author  idea
*  @Date  created in 10:35 下午 2022/7/18
*/
public class TraceInfoConverter extends ClassicConverter {


    @Override
    public String convert(ILoggingEvent iLoggingEvent) {
        CommonRequest request = (CommonRequest) CommonRequestContext.get(RequestContentConstants.COMMON_REQUEST);
        return request == null ? null : convertFromRequest(request);
    }

    /**
* 格式化日志
*
*  @param  request
*  @return
 */
public String convertFromRequest(CommonRequest request) {
        StringBuilder builder = new StringBuilder();
        builder.append("traceId:").append(request.getTraceId())
                .append(",").append("userId:").append(request.getUserId());
        return builder.toString();
    }
}
```

从线程上下文拿出全链路的 id 之后，通过重写 ClassicConverter 的 convert 函数逻辑即可。但是要注意，要想让这个组件生效的话，我们需要在 logback 的配置中指定这个 conversionRule 的属性，如下图所示：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c82c1b6465e0404e9a9a2124c50fd1dc~tplv-k3u1fbpfcp-watermark.image?)

## 课后小节

本节我们重点介绍了日志框架在底层的一些实现原理，主要分为同步记录和异步记录两种类型。

同步记录在进行日志打印时需要加入锁，来防止一些并发写入时导致的数据错乱问题，例如多个线程写同一行记录导致的问题。

异步写入的逻辑是，先将要打印的日志内容放入一条阻塞队列中，接着由一个单独的线程去读取，并将它们逐个取出打印到日志中去。



## 课后思考

**上节课思考**

在上一节中，我们留下了一道思考题，是关于异步线程池的可靠性问题。

其实本身在使用线程池的时候，我们就需要考虑到它并不是一个完全可靠的组件，有可能会存在数据丢失的情况发生，因此在使用这种组件的时候需要结合具体的业务场景去落地。

如果你希望既可以异步处理，也可以保证最终的数据准确性，那么我推荐你使用类似 RocketMQ 这种组件，当任务处理失败之后，RocketMQ 会过段时间重新发送一次消息，直到任务处理完毕为止。

**本节课思考**

你在工作中有遇到过日志包冲突的坑嘛，欢迎大家在评论区中展开讨论。
