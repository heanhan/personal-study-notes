在前边的章节中，我们深入学习了 synchronized 和 ReentrantLock 锁是如何避免线程安全问题的，但是之前我们所讨论的场景，都是在单个进程内所发生的情况，然而在如今大多数的互联网应用中，服务的部署都会采用分布式架构的模式进行部署，这个时候如果多个进程同时对某个数据进行修改，就有可能会有数据一致性问题了。

为了方便大家理解，这里让我们一起看看下边这个应用场景。

假设有两个库存服务节点，节点要同时去执行库存扣减的操作。如果将库存变量读取到本地内存再进行判断，然后再执行扣减操作的话，可能会产生一些数据不一致的问题，例如下图所示：
![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/66f9f20861eb457085518ce49aa9d8fc~tplv-k3u1fbpfcp-watermark.image?)

最终会导致原本库存只有一件物品，结果发生了两次扣减库存的操作，从而产生了业务异常。

如果我们在访问 stock 的时候，加入一个拦截的屏障，一次只允许一个请求访问 stock 变量的话，这个问题就可以很好解决了。


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/976fe09936da436cbfb321c910e58721~tplv-k3u1fbpfcp-watermark.image?)
而这里我们所说的拦截的屏障，可以形象地把它比作为是一把锁，一次只有一把“钥匙”可以开启，剩下的需要进行等待，那么如何去实现这个锁呢？下边我列出了几种业界常见的技术方案，一起来讨论学习下。

## **基于MySQL表实现分布式锁**

这种方案的设计思路是，通过往MySQL中插入一条记录，然后定义其中的某个字段用于表示锁是否被占用，例如下图所示：

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/615c6982e9004da68bf5ef241293c260~tplv-k3u1fbpfcp-watermark.image?)

加锁和释放锁时，可以采用执行 SQL 的方式去实现：

**加锁操作**

```
update t_lock set lock_status=1 where id=1 and lock_status=0; 
```

**释放锁操作**

```
update t_lock set lock_status=0 where id=1 and lock_status=1;
```

但是基于 MySQL 这种方式去实现分布式锁的话，其实性能方面是比较差的，对于一些并发度比较高的场景，会出现性能瓶颈问题，所以互联网应用通常都不会采用这种技术手段。

## 基于 Redis 去实现分布式锁

基于 Redis 实现分布式锁是互联网企业比较常见的技术手段，之所以要使用 Redis 作为分布式锁，我认为这主要还是和 Redis 的以下两点有关：

**单线程处理指令，没有线程安全问题**

Redis 在接收外界请求命令和一些 IO 操作时，实际上只是通过一个单线程去接收的，而它的多线程设计主要还是应用在一些主从复制、持久化、数据清理等方面。Redis 自身就是在处理命令方面采用了单线程模型，所以可以保证每个读写指令都按照先后顺序依次执行。

**性能高效**

Redis 本身存在着非常高的性能特性，这一点我认为主要有三个原因：

-   第一个是因为它是在内存中进行计算的，而计算机中内存的读写速率就比普通磁盘（这里不和 ssd 固态硬盘比较）的读写速率高许多。

-   第二个和 Redis 的单线程模型有关，假设 Redis 采用了多线程思路去设计对指令的处理，那么就需要考虑很多的线程安全问题，例如两个线程同时对一个队列指令 lpush 操作，那么谁先谁后就需要通过加锁来解决，这样就会对写效率造成影响。

-   第三个和 Redis 采用的 io 模型有关系，部署在 Linux 环境下的 Redis，在底层处理外界指令时，主要采用了 epoll 函数，这个函数在面对众多连接时采用了轮询的方式，如果当 epoll 访问到一个没有任何数据传送过来的连接的话，就会轮询下一个连接，而不是在那里堵塞等待。

    而如果一旦有数据抵达网卡的话，epoll 模型的底层会收到一个通知信号。这是因为 epoll 模型在初始化的时候就会和计算机的网卡驱动设备建立好一个回调通知关系，一旦监听到网卡设备上有 fd 请求触发，就会触发一个回调函数，这个回调函数在 Linux 内核中叫 ep_poll_callback ，它会将发生的事件添加到 rdlist 双链表中，而在 Redis 的底层，主要就是在对这个队列中回调过来的数据进行处理的。

好了，现在我们了解了为什么要使用 Redis 实现分布式锁，下边我们一起看看如何采用 Redis 实现分布式锁。

## 如何采用 Redis 实现分布式锁？

很多人都会用 setNx 指令来实现分布式锁，setNx 的语义就只允许一次成功设置，如果其他的请求还想尝试执行该指令的话，就会失败。接下来让我们看看下边这个案例实现分布式锁的思路：

-   **分布式锁版本一**
```
boolean status = redisService.setNx(key);
if(status){
//执行业务逻辑
}
```

这段代码看起来似乎很简单，如果加锁成功了，才可以处理业务逻辑，但是这有个致命问题，就是 setNx 指令自身是不支持 key 的过期时间指定的，当首次 setNx 执行成功之后，下一次请求则会返回失败结果，所以我们还需要加一个删除锁的操作。现在让我们来看看第二版本的分布式锁实现思路。

-   **分布式锁版本二**

```java
boolean status = redisService.setNx(key);
if(status){
//执行业务逻辑 (内部会判断是否该线程已经加锁成功了)
   redisService.del(key);
}
```

这把锁虽然实现了删除逻辑，但是假设业务逻辑处理到一半的过程中出现了异常中断，就会导致锁删除失败，所以我们可以加入一个 try-catch-finally 来进行优化。

-   **分布式锁版本三**

```java
boolean status = redisService.setNx(key);
if(status){
    try {
        //...业务逻辑处理
    } catch(Exception e) {
        //...
    } finally {
        //删除锁 (内部会判断是否该线程已经加锁成功了)
        redisService.del(key);
    }
}
```

这个版本实现的分布式锁，大致看起来似乎没什么问题，即保证了业务逻辑的单线程访问，同时也能确保在异常发生时执行删除锁操作。

这里我们再进一步思考，假设在 finally 处执行 Redis 删除操作时，出现了网络异常，请求失败了，那么这把锁该如何处理？接下来我们来看版本四中的分布式锁。

-   **分布式锁版本四**

这里我们可以给 setNx 操作加上一个让锁自动过期的时间限制。具体操作如下：

```java
boolean status = redisService.setNx(key);
if(status){
    try {
      //给锁进行一个过期时间的定义
      boolean expireStatus = redisService.expire(key,3,TimeUnit.SECOND);
      if(expireStatus){
        //...业务逻辑处理
      }
    } catch(Exception e) {
        //...
    } finally {
        //删除锁 (内部会判断是否该线程已经加锁成功了)
        redisService.del(key);
    }
}
```

有了过期机制之后，即使锁删除失败了，这把锁也会在预计的时间内自动失效，在失效时间过去之后，也就不会影响第二次加锁的操作。

但是这里似乎存在一个问题，如果说 expireStatus 操作失败了，del 操作也失败了，这把锁就会一直都存在，**那么Redis是否提供什么途径，能够将setNx和expire都合在一次执行？** 其实是可以的，下边我们来看分布式锁版本五。

-   **分布式锁版本五**

```java
boolean setKeyNx = true;
boolean setKeyExpire = true;
boolean status = redisService.set(key,setKeyNx,setKeyExpire,3,TimeUnit.SECOND);
if(status){
    try {
        //...业务逻辑处理
      }
    } catch(Exception e) {
        //...
    } finally {
        //删除锁 (内部会判断是否该线程已经加锁成功了)
        redisService.del(key);
    }
}
```

在 Redis 的 2.6.12 版本中，set 指令支持通过参数传递，让 setNx 操作和 Expire 操作以一个原子性的指令传递给 Redis，其具体的语法指令如下所示：

```
SET key value [NX | XX] [GET] [EX seconds | PX milliseconds |
  EXAT unix-time-seconds | PXAT unix-time-milliseconds | KEEPTTL]
```

现在来看，似乎已经避免了锁设置成功却过期失效的情况了，但这样依然存在一些问题，让我们来看下边这个场景。假设某天，有个业务场景的执行时间超过了锁的存活时间，那么就会导致这把锁在业务执行的过程中失效了，从而导致下一个线程也执行到了原先被锁保护的代码块。

```java
boolean setKeyNx = true;
boolean setKeyExpire = true;
boolean status = redisService.set(key,setKeyNx,setKeyExpire,3,TimeUnit.SECOND);
if(status){
    try {
        //...业务逻辑处理
      }
    } catch(Exception e) {
        //...
    } finally {
        //删除锁 (内部会判断是否该线程已经加锁成功了)
        redisService.del(key);
    }
}
```

那么，有什么好的思路去对这种场景进行处理吗？其实也是有办法的，我们可以在后台启动一个线程，对锁的过期时间做判断，如果锁的存活时间只剩下 25% 了，那么我们可以对锁重新执行过期操作。具体的流程如下图所示：

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce687da1ff6e4a6096fb0ed466f414b2~tplv-k3u1fbpfcp-watermark.image?)

下边是一段伪代码，后台启动一个线程，定时将仍为过期的锁进行续命操作。
```java
void doSomeBiz(String orderId){
    boolean setKeyNx = true;
    boolean setKeyExpire = true;
    boolean status = redisService.set(orderId,setKeyNx,setKeyExpire,3,TimeUnit.SECOND);
    if(status){
        try {
            //...业务逻辑处理
          }
        } catch(Exception e) {
            //...
        } finally {
            //删除锁 (内部会判断是否该线程已经加锁成功了)
            redisService.del(key);
        }
    }
}

//扫描所有分布式锁类型的key，然后进行扫描，对于即将过期的key就进行续命操作。
class  WatchThread implements Runnable {

    @Override
    public void run() {
        while(true){
            Set<String> lockKeySet = doScanExpireLock();
            for (String lockKey : lockKeySet) {
                //检测锁的过期时间是否只剩下25%了，如果是则需要给锁进行下续命的操作。
                if(checkLockNeedResetExpireTime(lockKey){
                   //如果锁依然存在
                   reSetLockExpireTime(lockKey);
                }
            }
        }
    }
}
```

不过我建议对于这种锁续命的操作，最好是可以做成参数可配置的方式，因为一旦开启锁续命之后，就有可能会产生锁一直堵塞的情况（例如有人在业务代码中写了一个线程睡眠的情况），所以这个命令需要结合实际业务场景来定义使用。

好了，现在我们基本已经知道如何实现一把合格的分布式锁了，接下来进入到代码实战环节吧。

## **实战实现分布式锁**

首先我们需要定义一个分布式锁的接口：

```java
public interface IDistributionLock {


    /**
     * 加锁
     *
     * @param key 锁的名字
     * @return
     */
    Boolean tryLock(String key);


    /**
     * 加锁(不会续命)
     *
     * @param key 锁的名字
     * @return
     */
    Boolean tryLockNotReSet(String key);


    /**
     * 加锁
     * @param key 锁的key
     * @param tryTimes 重试次数
     */
    Boolean tryLock(String key,int tryTimes);

    /**
     * 释放锁
     *
     * @param key
     * @return
     */
    Boolean releaseLock(String key);
}
```

然后是基于这个接口去设计具体的锁实现逻辑，具体代码如下所示：

```java
public class DistributionLock implements IDistributionLock {

    private IRedisService redisService;
    private ExecutorService watchTaskPool = Executors.newFixedThreadPool(1);

    public DistributionLock(IRedisService redisService) {
        this.redisService = redisService;
        LOGGER.info(" =================== [DistributionLock] init WatchKeyTask  =================== ");
        watchTaskPool.execute(new WatchKeyTask());
    }

    private static final Logger LOGGER = LoggerFactory.getLogger(DistributionLock.class);
    //用于记录每个锁的名字，方便后期进行续命的时候操作
    private static Set<String> lockKeySet = new HashSet<>();
    //记录每个线程是否都有加锁成功过
    private static LockStatusThreadLock lockStatusThreadLock = new LockStatusThreadLock();
    private static final int DEFAULT_LOCK_TIME = 5;
    private static final int RESET_EXPIRE_TIME = 1;

    @Override
    public Boolean tryLock(String key) {
        //默认锁的超时时间是5秒，
        if (redisService.setNx(key, 1, DEFAULT_LOCK_TIME)) {
            //加锁成功，则记录当前线程获取锁成功
            lockStatusThreadLock.set(true);
            //记录到set中，方便续命使用
            lockKeySet.add(key);
            LOGGER.info(" =================== [DistributionLock] tryLock success =================== ");
            return true;
        } else {
            LOGGER.info(" =================== [DistributionLock] tryLock fail =================== ");
            return false;
        }
    }

    @Override
    public Boolean tryLockNotReSet(String key) {
        //默认锁的超时时间是5秒，
        if (redisService.setNx(key, 1, DEFAULT_LOCK_TIME)) {
            //加锁成功，则记录当前线程获取锁成功
            lockStatusThreadLock.set(true);
            LOGGER.info(" =================== [DistributionLock] tryLock success =================== ");
            return true;
        } else {
            LOGGER.info(" =================== [DistributionLock] tryLock fail =================== ");
            return false;
        }
    }


    /**
     * 给锁进行续命的定时任务
     */
    class WatchKeyTask implements Runnable {

        @Override
        public void run() {
            while (true) {
                try {
                    Thread.sleep(3000);
                    LOGGER.debug("[DistributionLock] exec WatchKeyTask");
                    for (String lockKey : lockKeySet) {
                        long expireTime = redisService.ttl(lockKey);
                        //这个时候表明key已经不存在了
                        if (expireTime == -2) {
                            //二次删除确认
                            lockKeySet.remove(lockKey);
                            continue;
                        }
                        //如果锁的存活时间只剩下了25%，而且此时还是处于加锁状态，则进行续命
                        if (RESET_EXPIRE_TIME > expireTime) {
                            //如果此时锁已经被删除了，这里也不要紧
                            //如果此时锁已经被另一个线程拥有了，这里新线程的锁的时间会被重置一次，不过不影响
                            redisService.expire(lockKey, DEFAULT_LOCK_TIME, TimeUnit.SECONDS);
                            LOGGER.info("[DistributionLock] expire lock {}", lockKey);
                        }
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    @Override
    public Boolean tryLock(String key, int tryTimes) {
        int i = 0;
        while (i < tryTimes) {
            if (tryLock(key)) {
                return true;
            }
            i++;
        }
        return false;
    }

    @Override
    public Boolean releaseLock(String key) {
        try {
            if (lockStatusThreadLock.get()) {
                LOGGER.info("[DistributionLock] releaseLock, key is {}", key);
                redisService.del(key);
                return true;
            }
        } catch (Exception e) {
            LOGGER.error("[DistributionLock] releaseLock has error,e is ", e);
        } finally {
            //如果锁不需要续命，这里执行一次也没有什么影响
            lockKeySet.remove(key);
            lockStatusThreadLock.remove();
        }
        return false;
    }
}
```

这段代码中我大概解释几个位置：

-   LockStatusThreadLock 这个类，实际上是一个继承了 TransmittableThreadLocal 类的线程本地变量类，它主要记录了当前现场是否加锁成功。之所以使用 TransmittableThreadLocal，是考虑到了有可能会存在 在主线程加锁，线程池中解锁的这类场景。
-   WatchKeyTask 这个线程是一个定时任务，主要负责给需要进行续命的锁进行过期时间的重置操作。这里会选择在每隔 3 秒扫描一次所有需要续命的锁，如果过期时间只剩下锁生存时间的 25%，就会重置有效时间。

<!---->

-   releaseLock 释放锁会在 finally 中将本地线程变量清空，同时将续命记录移除（如果有记录的话）。

<!---->

-   tryLockNotReSet 接口中并不支持锁的续命操作，这个函数的调用主要由业务方来决定。

这把锁的底层，使用的是 Redis 的 setNx 指令去实现，底层如下：

```java
@Override
public Boolean setNx(String key, Object value, int expireSecond) {
    try (Jedis jedis = iRedisFactory.getConnection()) {
        String result = jedis.set(key, String.valueOf(value), new SetParams().nx().ex(expireSecond));
        return "OK".equals(result);
    } catch (Exception e) {
        log.error("jedis setNx has error, error is ", e);
    }
    return false;
}
```

这里我直接使用了 set 指令，然后额外传入了一些 SetParams 参数，从而保证指令的原子特性。

下边是一个用锁保护扣减库存操作的代码实现，这段代码中的核心逻辑是，先从 Redis 中读取库存的数目，如果库存为 0，则打印“库存已经扣减完毕”的字样。

```java
@Service
public class TestService {

    @Resource
    private IDistributionLock distributionLock;
    @Resource
    private IRedisService redisService;

    public static String LOCK_KEY = "lock_key";

    /**
     * 模拟扣减库存
     */
    public void doDecrStoreWithLock() {
        boolean lockStatue = false;
        try {
            lockStatue = distributionLock.tryLock(LOCK_KEY);
            if (lockStatue) {
                String storeKey = "store";
                int store = redisService.getInt(storeKey);
                if (store == 0) {
                    System.out.println("库存已经扣减完毕");
                } else {
                    //如果库存尚有剩余，这里直接扣减
                    redisService.decr(storeKey);
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            if (lockStatue) {
                distributionLock.releaseLock(LOCK_KEY);
            }
        }
    }

    /**
     * 模拟扣减库存 没有锁的保护
     */
    public void doDecrStoreNotWithLock() {
        String storeKey = "store";
        int store = redisService.getInt(storeKey);
        if (store == 0) {
            System.out.println("库存已经扣减完毕");
        } else {
            //如果库存尚有剩余，这里直接扣减
            redisService.decr(storeKey);
        }
    }


}
```

从这两段代码中，我们不难发现，如果是多个不同的 Java 进程同时执行扣减库存操作的话，就会出现数据不一致的问题。为了验证不加锁和加锁在不同并发度下的区别，我新建了一个 Controller 供 http 请求调用，以及一个自定义的负载均衡器，用于进行多节点的并发测试。

**Controller层的代码如下所示：**

```java
@RestController
@RequestMapping(value = "/test")
public class TestController {

    @Resource
    private TestService testService;

    @GetMapping(value = "/doDecrStoreNotWithLock")
    public void doDecrStoreNotWithLock(){
        testService.doDecrStoreNotWithLock();
    }

    @GetMapping(value = "/doDecrStoreWithLock")
    public void doDecrStoreWithLock(){
        testService.doDecrStoreWithLock();
    }
}
```

**然后是一个自定义的负载均衡器组件代码，具体如下：**

```java
@RequestMapping(value = "/cluster")
@RestController
public class ClusterController {

    private static final String NOT_LOCK_DECR_URL_1 = "http://localhost:8081/test/doDecrStoreNotWithLock";
    private static final String NOT_LOCK_DECR_URL_2 = "http://localhost:8082/test/doDecrStoreNotWithLock";
    private static final String LOCK_DECR_URL_1 = "http://localhost:8081/test/doDecrStoreWithLock";
    private static final String LOCK_DECR_URL_2 = "http://localhost:8082/test/doDecrStoreWithLock";


    /**
     * 模拟负载均衡请求
     *
     * @return
     */
    @GetMapping(value = "/decr")
    public Object decr(boolean lockState) {
    //每次请求都会随机转发到不同的端口
        int result = RandomUtils.nextInt(0, 2);
        if (result == 1) {
            if (lockState) {
                HttpUtil.doGet(LOCK_DECR_URL_1);
            } else {
                HttpUtil.doGet(NOT_LOCK_DECR_URL_1);
            }
        } else {
            if (lockState) {
                HttpUtil.doGet(LOCK_DECR_URL_2);
            } else {
                HttpUtil.doGet(NOT_LOCK_DECR_URL_2);
            }
        }
        return null;
    }

}
```

这个负载均衡器组件主要给外界进行并发测试使用，这里我使用的是 ab 指令工具来进行的并发模拟，首先是对没有加锁的接口进行并发测试。

**测试相关数据具体如下：**

-   扣减库存的 Java 进程数：2
-   自定义负载均衡器数：1
-   测试方式：通过使用 ab 命令发送请求，如 ab -n200 -c2 'http://localhost/cluster/decr?lockState=false'

下边是我进行了几次并发测试所得到的结果：

| **请求次数** | **并发次数** | **初始库存** | **结束库存** |
| -------- | -------- | -------- | -------- |
| 200      | 1        | 100      | 0        |
| 200      | 2        | 100      | -100    |
| 200      | 10       | 100      | -100    |

从结果可以看出，在分布式应用场景中，这种将库存加载到本地进行判断，然后再进行扣减的操作，如果没有锁的保护，只要稍微有些并发请求，就会出现数据不一致的问题。

现在我们看看加入了分布式锁之后的测试效果，同样还是使用 ab 指令进行压力测试：

| **请求次数** | **并发次数** | **初始库存** | **结束库存** |
| -------- | -------- | -------- | -------- |
| 200      | 1        | 100      | 0        |
| 200      | 2        | 100      | 25       |
| 500      | 2        | 100      | 63       |
| 1000     | 5        | 100      | 0        |

通过这个并发测试的结果，我们看出，使用了分布式锁进行保护之后，至少能够保证库存不会出现超扣的情况。通过测试来看，这把锁在多个进程进行并行修改数据时，确实可以起到安全防护的效果。另外如果我们需要测试锁的续命效果，可以在业务代码中执行一些 sleep 的操作，这块的细节大家可以在课后进行尝试测试。




## 课后小节

本节，我们重点介绍了如何通过 Redis 实现一把分布式锁，以及实现过程中可能会遇到的问题，具体如下所示：

-   **分布式锁在实现过程中，该如何实现其正常的关闭？**

采用的是线程本地变量技术，用于记录当前线程是否持有过锁，如果有才会进行释放操作。

-   **分布式锁的超时问题应该如何处理？**

后台开启一个定时扫描线程，会检测需要进行续命的锁信息，如果扫描过程中，发现某把需要续命的锁的剩余有效时间只剩下 25%，而且此时还在进行业务处理操作中的话，就重置其过期时间为原先状态。
-   **如何保证加锁是一个原子性操作**

这块我们采用的是通过 set 命令，从而保证 setNx 和 expire 命令通过一条 Redis 指令就能够实现效果。

**本章节源代码：**
```
https://gitee.com/IdeaHome_admin/concurrence-programming-lession/tree/master/src/main/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B16
```

## 课后思考

**上节课答疑**

上节课中，我们留下了一道思考题，是关于工作中常用的分库分表中间件，以及在使用过程中会遇到哪些问题，下边我整理了一些资料，供大家参考。

| **中间件名称**     | **特点**                                                                                                                                                                                                                         |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| MyCat         | 是一个实现了 MySQL 协议的服务器。前端用户可以把它看作是一个数据库代理中间件，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。支持读写分离、分布式事务、分库分表策略等，对于上游业务层是透明的，但是存在单点的性能瓶颈。 |
| ShardingJdbc  | 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。支持分库分表策略，读写分离，分布式 id 生成，只支持非跨库的事务，可以和众多 ORM 框架进行接入，采用的是业务端代理方式，                                               |
| ShardingProxy | 定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前先提供 MySQL 版本，它可以使用任何兼容 MySQL 协议的访问客户端(如：MySQL Command Client，MySQL Workbench等)操作数据，对 DBA 更加友好。适用于任何兼容 MySQL 协议的客户端。向应用程序完全透明，可直接当作 MySQL 使用。                                 |




**本节课思考**

本节，我们所介绍的只是基于 Redis 实现分布式锁，这种途径是目前大多数互联网公司都会使用的技术方案，业界也有更加成熟的组件来实现，例如 Redission。

最后我留一道课后思考题，基于 ZK 或 Redis 去实现的分布式锁有什么区别？欢迎在评论区中进行讨论。

