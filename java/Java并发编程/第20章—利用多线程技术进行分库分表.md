在互联网应用场景中，随着业务场景的发展，数据量的膨胀，分库分表会是一个非常常见的技术解决手段。其实分库分表的基本步骤总结下来大概就是下边三步：

1.  设计片键；
2.  数据迁移；
3.  数据矫正。

本节我们围绕一个分库分表的案例一步步分析下，重点会放在数据迁移和矫正这块，关于片键的选择，其实会和业务场景有强关联。下边让我们来看看这个分表的实战案例吧。

## **业务背景**

有一张用户聊天表，存储的结构如下所示：

```
CREATE TABLE `t_user_message` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `user_id` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '发信方id',
  `object_id` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '收信方id',
  `relation_id` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '关联id',
  `is_read` tinyint(2) unsigned NOT NULL DEFAULT '0' COMMENT '是否已读（0未读，1已读）',
  `sid` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '消息条数',
  `status` tinyint(2) unsigned NOT NULL DEFAULT '1' COMMENT '状态（0无效 1有效）',
  `content` varchar(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL DEFAULT '' COMMENT '消息内容',
  `type` tinyint(2) unsigned NOT NULL DEFAULT '0' COMMENT '类型（0文本，1语音，2图片，3视频，4表情，5分享链接）',
  `ext_json` varchar(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL DEFAULT '' COMMENT '扩展字段',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`),
  KEY `idx_user_id` (`user_id`) USING BTREE COMMENT '发信方id索引',
  KEY `idx_object_id` (`object_id`) USING BTREE COMMENT '收信方id索引',
  KEY `idx_relation_id` (`relation_id`) USING BTREE COMMENT '关联id索引'
) ENGINE=InnoDB AUTO_INCREMENT=100009 DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='用户消息表';
```

随着业务的发展，预估一个月后数据量会膨胀到千万级别，于是机智的开发同学开始需要思考如何对该数据表进行拆分。

## 设计片键

设计片键的主要思路得结合业务场景，目前的消息查询业务场景主要是：**按照用户 id 查询两个人的聊天信息。**

如果 A 和 B 聊过天，那么表中的记录就会有两条数据，如下图所示：


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/881db7ead6e64a67825c4ac301a3ba26~tplv-k3u1fbpfcp-watermark.image?)

随着业务规模的不断扩展，单日的增量数据达到了四十万的规模，而且预估后边的增量趋势会越来越猛，接近到百万+的规模，所以我们很有必要对消息数据进行分库分表存储。

## **数据迁移**

在进行用户聊天信息分表的过程中，主要是将单表中的数据利用多线程机制，先加载到内存中。具体的分工步骤可以如下所示。不同的线程读取表中不同部分的数据，这个可以根据 SQL 中的 limit 操作去限制查询范围。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15b036c9c6954d31aad794ab6c48bb1e~tplv-k3u1fbpfcp-watermark.image?)

接着我们可以将读取出来的数据慢慢地写入到分表当中，具体细节流程可以用下图来解释。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4c0ce94267d47b5aa99b58552d71d73~tplv-k3u1fbpfcp-watermark.image?)

其实这就是一个最简单的分表流程，首先从源表中查询数据，接着按照片键来进行筛分，这个实现过程我们可以结合团队的实际技术栈情况来实现。但是在进行分表的过程中，我们很难避免会有增量数据的产生，什么是增量数据呢？来看看下边这张图，相信你就懂了：

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9949ac1540444549a33a2a0c0ad4d7d8~tplv-k3u1fbpfcp-watermark.image?)

当前我们在进行分表步骤的过程中，可能会有新的数据写入或者是更新，而这些数据可能会对一些已经被写入分表的数据进行更新，例如下图所示：


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/31e4228e738d4ae4be1b3f809404113e~tplv-k3u1fbpfcp-watermark.image?)

在执行分表的过程中，先将 user_id=1 的数据写入到新的表，接着一条更新的 SQL 来到了源表中，修改了 user_id=1 的数据，从而导致分表中的数据是脏数据。那么我们该如何应付这种场景呢？

这个时候就有了我们的 **数据纠正**环节了。

## 数据矫正

这个时候，我们可以设计这么一种思路，如同下表所示：


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0ddc582f3b29411da69aa973de8e7a29~tplv-k3u1fbpfcp-watermark.image?)

**我们可以专门建立一个记录点，当在执行分表程序的过程中，如果源表有发生写的操作，那么记录下写操作的SQL，当整个分表程序执行完之后，再将写操作的记录回放到分表中即可。** 

但是，这个回放的操作可能不止一次，所以需要有一个检测机制，例如在回放 SQL 的过程中，记录是否有新的请求去修改源表。这个过程需要反复执行，直到最后精准无误之后，再将数据源从源表切换到分表中。

看到这里，你可能会有些许疑惑，我们该如何记录下 SQL 操作呢？别急，其实业界很早就已经有了类似的中间件技术了。阿里巴巴有一款叫做 Canal 的中间件就是专门干这个的。

Canal 可以专门用于模拟数据库的一个 Slave 节点，然后接收 Master 节点的 binlog 日志。我们可以利用 Canal 将迁移过程中产生的写数据操纵先记录到一个 MQ 中进行暂存，当迁移完成之后，再将 MQ 缓存的数据给消费掉，从而完成增量数据的同步。

更多关于 Canal 中间件的技术原理我就不在这里过多展开了，感兴趣的同学可以在网上搜索看看关于 Canal 的 [Github地址](https://github.com/alibaba/canal)。

到这里，一个分库分表的基本思路就算介绍结束了。那么在完成了分库分表之后，查询又会有哪些变化呢？

**分表查询 SQL 的调整**

下边是一套非常简单的基于 MyBatis 来做分表的实现方式：

```Java
@Override
public void doQueryFromSplitTable(Long userId) {
    Map<String, Object> paramMap = new HashMap<>(2);
    paramMap.put("userId", userId);
    //定义分表的切片
    paramMap.put("table_index", convertTableIndexName( String.valueOf( userId % 10000)));
    List<UserMessagePO> userMessagePOS = getBaseMapper().selectByUserId(paramMap);
    System.out. println(userMessagePOS);
}
```

对应的 xml 配置如下：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="并发编程15.分库分表.dao.UserMessageMapper">

    <select id="selectByUserId" parameterType="java.util.Map" resultType="并发编程15.分库分表.po.UserMessagePO">
        select * from t_user_message_${table_index} where user_id=#{userId}
    </select>
</mapper>
```

原理非常简单，就是将片键的值和分表的数目进行去余，得出最终需要查询的表，执行 SQL 查询数据即可。

这种实现方式虽然简单易懂，但其实是属于硬编码的方式进行实现的，首先需要我们通过硬编码的方式来修改 SQL 中的表名，假设项目中有一百处位置写的是 **t_user_message**，那么我们就得修改一百处的代码，操作起来整体也比较费劲。

而在 MyBatis-Plus 框架中，其实内部就已经支持了对于分表后的数据库查询，它的设计思路是在执行 SQL 查询之前，会通过一个本地线程变量来存储片键的数值，最终在拼接 SQL 时，对表名进行修改。

下边是一个简单的使用案例：

```java
@Override
public void doQueryFromSplitTable(Long userId) {
    Map<String, Object> paramMap = new HashMap<>(2);
    paramMap.put("userId", userId);
    //定义分表的切片
    TableIdContext.setId(userId);
    List<UserMessagePO> userMessagePOS = getBaseMapper().selectByUserId(paramMap);
    System.out.println(userMessagePOS);
}
```

这段代码其实是将偏键的数值设置到一个线程本地变量中，这个线程本地变量的设计基本如下：

```
public class TableIdContext {

    //使用ThreadLocal防止多线程相互影响，用于存储分表的片键
    public static ThreadLocal<Long> id = new ThreadLocal<>();

    public static void setId(Long idValue) {
        id.set(idValue);
    }

    public static Long getId(){
        return id.get();
    }

    public static void clean(){
        id.remove();
    }
}
```

之所以要设计这个存储分表 id 的上下文，就是希望在 MyBatis-Plus 执行表查询时，能够从线程上下文中提取出对应的片键 id 出来，然后生成实际需要查询的表名称，这块的逻辑主要展现在下边这个 IdModTableNameParser 类里面：

```
public class IdModTableNameParser implements TableNameHandler {

    private Integer mod;

    public IdModTableNameParser(Integer mod) {
        this.mod = mod;
    }

    @Override
    public String dynamicTableName(String sql, String tableName) {
        Long idValue = TableIdContext.getId( );
        if (idValue == null) {
            throw new RuntimeException("请设置id值");
        } else {
            String suffix = String.valueOf( idValue % mod);
            //这里清除ThreadLocal的值，防止线程复用出现问题
            TableIdContext.clean( );
            return tableName + "_" + suffix;
        }
    }
}
```

IdModTableNameParser 这个类实现了 MyBatis-Plus 内部的 TableNameHandler 接口，这个接口的作用是用于定义一些分表规则中的表名匹配机制，具体的匹配定义是在将 IdModTableNameParser 类注入到 Spring 容器的时候才设定的，注入部分代码如下：

```
@Configuration
public class TableNameConfig {

    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor(){
        MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor();
        DynamicTableNameInnerInterceptor dynamicTableNameInnerInterceptor = new DynamicTableNameInnerInterceptor();
        Map<String, TableNameHandler> map = new HashMap<>();
        //指定表名和分表的数目
        map.put(T_USER_MESSAGE.getName(),new IdModTableNameParser(T_USER_MESSAGE.getMod()));
        dynamicTableNameInnerInterceptor.setTableNameHandlerMap(map);
        //拦截起注入
        mybatisPlusInterceptor.addInnerInterceptor(dynamicTableNameInnerInterceptor);
        return mybatisPlusInterceptor;
    }

}
```

看到这里，细心的朋友会发现，这个分表的处理器，是以一个拦截器的方式被注入到 MyBatis 里面的，那么它又是如何拦截的呢？这部分就需要我们从源代码的角度去发掘了。

**DynamicTableNameInnerInterceptor的底层实现逻辑**

其实在 MyBatis-Plus 的内部，有一个叫做 DynamicTableNameInnerInterceptor 的拦截器，这个拦截器会拦截每个查询 SQL，然后修改它所查询的表名字，这块的细节我在下方的源代码中贴了出来供大家查看：

```
/*
 * Copyright (c) 2011-2020, baomidou (jobob@qq.com).
 * <p>
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 * <p>
 * https://www.apache.org/licenses/LICENSE-2.0
 * <p>
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */
package com.baomidou.mybatisplus.extension.plugins.inner;

import com.baomidou.mybatisplus.core.plugins.InterceptorIgnoreHelper;
import com.baomidou.mybatisplus.core.toolkit.PluginUtils;
import com.baomidou.mybatisplus.core.toolkit.TableNameParser;
import com.baomidou.mybatisplus.extension.plugins.handler.TableNameHandler;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.apache.ibatis.executor.Executor;
import org.apache.ibatis.executor.statement.StatementHandler;
import org.apache.ibatis.mapping.BoundSql;
import org.apache.ibatis.mapping.MappedStatement;
import org.apache.ibatis.mapping.SqlCommandType;
import org.apache.ibatis.session.ResultHandler;
import org.apache.ibatis.session.RowBounds;

import java.sql.Connection;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

/**
* 动态表名
*
*  @author  jobob
*  @since  3.4.0
*/
@Data
@NoArgsConstructor
@AllArgsConstructor
@SuppressWarnings({"rawtypes"})
public class DynamicTableNameInnerInterceptor implements InnerInterceptor {

    //根据表的名字，去搜索不同的分表处理器
    private Map<String, TableNameHandler> tableNameHandlerMap;

    @Override
    public void beforeQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {
        PluginUtils.MPBoundSql mpBs = PluginUtils.mpBoundSql(boundSql);
        if (InterceptorIgnoreHelper.willIgnoreDynamicTableName(ms.getId())) return;
        //其实这个changeTable的底层会有一个拦截表名的逻辑
        mpBs.sql(this.changeTable(mpBs.sql()));
    }

    @Override
    public void beforePrepare(StatementHandler sh, Connection connection, Integer transactionTimeout) {
        PluginUtils.MPStatementHandler mpSh = PluginUtils.mpStatementHandler(sh);
        MappedStatement ms = mpSh.mappedStatement();
        SqlCommandType sct = ms.getSqlCommandType();
        if (sct == SqlCommandType.INSERT || sct == SqlCommandType.UPDATE || sct == SqlCommandType.DELETE) {
            if (InterceptorIgnoreHelper.willIgnoreDynamicTableName(ms.getId())) return;
            PluginUtils.MPBoundSql mpBs = mpSh.mPBoundSql();
            //其实这个changeTable的底层会有一个拦截表名的逻辑
            mpBs.sql(this.changeTable(mpBs.sql()));
        }
    }

    //修改查询的表名字
    protected String changeTable(String sql) {
        //这个方法的目的是将一条SQL语句转换为多个Token段
        TableNameParser parser = new TableNameParser(sql);
        List<TableNameParser.SqlToken> names = new ArrayList<>();
        //在parser的内部会有一个List集合存储不同的Token段，然后accept函数的目的就是
        //在这些Token段中找到对应的表名
        parser.accept(names::add);
        StringBuilder builder = new StringBuilder();
        int last = 0;
        for (TableNameParser.SqlToken name : names) {
            int start = name.getStart();
            if (start != last) {
                builder.append(sql, last, start);
                String value = name.getValue();
                //value其实是表的名字
                TableNameHandler handler = tableNameHandlerMap.get(value);
                if (handler != null) {
                    //这里就会调用到我们自定义的分表名字处理器了
                    builder.append(handler.dynamicTableName(sql, value));
                } else {
                    builder.append(value);
                }
            }
            last = name.getEnd();
        }
        if (last != sql.length()) {
            builder.append(sql.substring(last));
        }
        return builder.toString();
    }
}
```

现在让我们整理下，MyBatis-Plus 内部提供的 TableNameHandler 接口是如何支持分表查询的，我绘制了一张流程图，如下所示：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/31e43480139f4ca2be75413601a48099~tplv-k3u1fbpfcp-watermark.image?)

现在，我们大概将分表的主要流程搞清楚了，下边来进行下简单的验证。这里我通过 Controller 来进行调用：

```java
@GetMapping(value = "/selectByUserId")
public List<UserMessagePO> selectByUserId(Long userId) {
    return userMessageService.selectByUserId(userId);
}
```

其内部的 service 层实现如下所示：

```
@Override
public List<UserMessagePO> selectByUserId(Long userId) {
    //定义分表的切片
    return DbUtils.queryFromSplitTable(userId, () -> getBaseMapper().selectByUserId(userId));
}
```

这里我将分表的查询逻辑封装在了一个 DbUtils 中，具体封装逻辑如下：

```
 /**
* 根据片键去查询数据
*
*  @param  splitKey 片键
*  @param  iSelect 执行查询操作
*  @param <T>
 *  @return
 */
public static <T> List<T> queryFromSplitTable(long splitKey, ISelect iSelect) {
    TableIdContext.setId(splitKey);
    Object result = iSelect.doSelect();
    return (List<T>) result;
}
```

对于 ISelect 的定义如下所示：

```
public interface ISelect {
    Object doSelect();
}
```

这部分的封装目前还是比较简单的，只需要传入一个片键的参数，同时注入一些查询的逻辑即可。最后我们来看看测试部分的逻辑。

用于测试的分表查询的数据内容如下：


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6fabff8acf7d4eca8710b3bc9713e29d~tplv-k3u1fbpfcp-watermark.image?)

我们往分表中存储了两条数据，接着测试 doQueryFromSplitTable 接口是否可以实现通过我们设计的表名处理器去搜索到对应的分表 **t_user_message_102** 。如果可以的话，则会有对应的数据出来，最后通过请求对应的接口，验证实际查询结果确实和预期相同：


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fc757589a6c84e9ebdc6661272ae082a~tplv-k3u1fbpfcp-watermark.image?)

到这里，一个简单的分表查询组件就算是设计的差不多了。但是在实际工作中，我们除了简单的关键字的查询之外，还有可能会遇到一些分表后的批量数据查询的逻辑，那么这种情况下，我们又该如何设计技术方案去解决呢，下边让我们一同来进行深入研究。

## **分表后的批量查询**

在进行分表后，如果我们需要执行批量查询的效果，又会发生什么样的事情呢，来看下边这个案例。在以前单表的业务场景中，需要查询指定用户最近 24 小时内是否有发送给对方，但对方未回复的消息，这种情况下通过 SQL 的查询大概如下：

```SQL
select * from t_user_message where user_id in (999,1123,9283,101) and `status`=1 and reply=0 
and create_time>=DATE_SUB(now(), INTERVAL 1 day);
```

如果在分表中进行查询的话，这样一次查询可能要划分为多条 SQL 去访问不同的表数据，例如下边所示：

```sql
select * from t_user_message_0001 where user_id in (100001) and `status`=1 and reply=0 
and create_time>=DATE_SUB(now(), INTERVAL 11 day);

select * from t_user_message_0002 where user_id in (100002) and `status`=1 and reply=0 
and create_time>=DATE_SUB(now(), INTERVAL 11 day); 

select * from t_user_message_0003 where user_id in (100003) and `status`=1 and reply=0 
and create_time>=DATE_SUB(now(), INTERVAL 11 day);

select * from t_user_message_0004 where user_id in (100004) and `status`=1 and reply=0 
and create_time>=DATE_SUB(now(), INTERVAL 11 day);
```

如果在进行分表查询的时候，我们采用的是单线程查询的话，这个查询的性能就会大打折扣，通常的做法是采用多线程，并发发送 SQL 查询，最终将结果聚合到一起，结果如下所示：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/59f3b17caf8e43859497f40427fcc9d4~tplv-k3u1fbpfcp-watermark.image?)

不知道看到这样一个流程之后，你是否会回想到之前课程中，我们所学习的 **CompletableFuture 技术。在 CompletableFuture 内部，提供了类似的功能，可以支持同时多线程查询数据库，然后将结果统一汇总之后才告知调用方查询的结果。** 于是我便在 DbUtils 中对分表后的批量查询做了些抽象，具体如下：

```
 /** 
  * 在分表中进行批量的id查询 
  * 
  * @ param s plitIds 片键id集合 
  * @ param t ableEnum 表名枚举 
  * @ param i Select 执行查询操作 
  * @ param  <  T > 
  * @ return   
  */ 
public static <T> List<T> queryFromSplitTable(List<Long> splitIds, TableEnum tableEnum, ISelect iSelect) {
    Set<Long> splitIdSet = new HashSet<>(splitIds);
    return queryFromSplitTable( splitIdSet, tableEnum, iSelect);
}

 /** 
  * 在分表中进行批量的id查询 
  * 
  * @ param s plitIdSet 片键id集合 
  * @ param t ableEnum 表名枚举 
  * @ param i Select 执行查询操作 
  * @ param  <  T >
  * @ return   
  */ 
  public static <T> List<T> queryFromSplitTable(Set<Long> splitIdSet, TableEnum tableEnum, ISelect iSelect) {
    List<T> finalList = new ArrayList<>();
    Map<String, List<Long>> tempMap = buildTableIndex( splitIdSet, tableEnum);
    CompletableFuture<List<T>>[] arr = new CompletableFuture[tempMap.size()];
    int i = 0;
    for (String tableIndex : tempMap.keySet()) {
        CompletableFuture<List<T>> completableFuture = CompletableFuture.supplyAsync( () -> {
            //定义分表的切片
            TableIdContext.setId( Long.valueOf( tableIndex));
            Object result = iSelect.doSelect();
            return (Collection<? extends T>) result;
        }).handle(new BiFunction<Collection<? extends T>, Throwable, List<T>>() {
            @Override
            public List<T> apply(Collection<? extends T> ts, Throwable throwable) {
                if (ts != null || !ts.isEmpty()) {
                    finalList.addAll(ts);
                }
                return finalList;
            }
        });
        arr[i++] = completableFuture;
    }
    //等待所有的查询结果到位
    CompletableFuture.allOf( arr).join();
    return finalList;
}

private static Map<String, List<Long>> buildTableIndex(Set<Long> splitIds, TableEnum tableEnum) {
    Map<String, List<Long>> splitIdMap = new HashMap<>();
    for (Long splitId : splitIds) {
        splitIdMap.computeIfAbsent(String.valueOf( splitId % tableEnum.getMod()), k -> new LinkedList<>()).add(splitId);
    }
    return splitIdMap;
}
```

例如下边这个功能，我们需要实现一个支持批量用户 id 进行查询未恢复消息的功能，那么就可以直接利用封装好的 DbUtils 进行查询：

```
@Override
public List<UserMessagePO> selectNotRead(Set<Long> userIdS) {
    //定义分表的切片
    return DbUtils.queryFromSplitTable(userIdS, TableEnum.T_USER_MESSAGE, () -> getBaseMapper().selectNotRead(userIdS));
}
```

在这个用例中，大概的思路是，将每个按照用户 id 查询的请求放入到各个独立的线程中，并且用 CompletableFuture 来管理各个线程的查询结果，最终将查询的结果统一汇总到一个 List 集合中。

但是在实际应用中，我们要尽量避免这种分表后的批量查询，因为它的底层是同时开启了多个线程进行查询的，对于性能的开销会比一般的单表查询要大许多。假设我们的 id 集合分散在了 100 张表中，那么批量查询就需要同时开启 100 个线程，所以在使用这种查询之前，我们需预估好查询的性能开销。



## 课后小结

本章节中，我们介绍了分库分表的一些思路，在分库分表过程中，如果有增量数据产生，我们可以利用 Canal 监听这个迁移过程中产生的增量数据，然后将这些增量数据利用 MQ 消息先暂存起来，待迁移过程结束后再同步到新的表中。

在面对分表查询时，文中介绍了 MyBatis-plus 中的 TableNameHandler 组件，通过二次开发这个组件，可以帮助我们实现分表的查询。不过这里我只是提供一种扩展思路给大家了解下，在实际业务中，大多数互联网公司会选择使用一些市面上已经集成好的分库分表中间件，例如 MyCat、ShardingJDBC 、ShardingSphere 等。

## 课后思考

**上节课答疑**

在上节课中，我们留下了一道思考题，是关于常见限流算法的思考题。下边我整理了一些关于限流算法的知识点，供大家查看：

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8864971cd98a4fc8bd769b8c22257a9e~tplv-k3u1fbpfcp-watermark.image?)






**本章节思考**

你在工作中，用到过哪些分库分表的中间件吗，你们会如何解决分库分表的业务场景，以及遇到的困难会有哪些？欢迎在评论区中讨论。
