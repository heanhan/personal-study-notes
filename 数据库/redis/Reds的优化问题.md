### Redis最佳实践：7个维度+43条使用规范，带你彻底玩转Redis

#### 如何使用redis更节省内存

1. **控制 key 的长度。**

   最简单的优化是控制key的长度

   在开发业务时，你需要提前预估整个 Redis 中写入 key 的数量，如果 key 数量达到了百万级别，那么，过长的 key 名也会占用过多的内存空间。

   所以，你需要保证 key 在简单、清晰的前提下，尽可能把 key 定义得短一些

   例如，原有的 key 为 user:book:123，则可以优化为 u:bk:123。

   这样一来，你的 Redis 就可以节省大量的内存，这个方案对内存的优化非常直接和高效

2. **避免存储 bigkey**

   除了控制 key 的长度之外，你同样需要关注 value 的大小，如果大量存储 bigkey，也会导致 Redis 内存增长过快。

   除此之外，客户端在读写 bigkey 时，还有产生性能问题

   - String：大小控制在 10KB 以下
   - List/Hash/Set/ZSet：元素数量控制在 1 万以下

3. **选择合适的数据类型**

    Redis 提供了丰富的数据类型，这些数据类型在实现上，也对内存使用做了优化。具体来说就是，一种数据类型对应多种数据结构来实现

4. **把 Redis 当作缓存使用**

   Redis 数据存储在内存中，这也意味着其资源是有限的。你在使用 Redis 时，要把它当做缓存来使用，而不是数据库。

   所以，你的应用写入到 Redis 中的数据，尽可能地都设置「过期时间」。

   业务应用在 Redis 中查不到数据时，再从后端数据库中加载到 Redis 中。

5. **实例设置 maxmemory + 淘汰策略**

   虽然你的 Redis key 都设置了过期时间，但如果你的业务应用写入量很大，并且过期时间设置得比较久，那么短期间内 Redis 的内存依旧会快速增长。

   如果不控制 Redis 的内存上限，也会导致使用过多的内存资源。

   对于这种场景，你需要提前预估业务数据量，然后给这个实例设置 maxmemory 控制实例的内存上限，这样可以避免 Redis 的内存持续膨胀。

   配置了 maxmemory，此时你还要设置数据淘汰策略，而淘汰策略如何选择，你需要结合你的业务特点来决定：

   - volatile-lru / allkeys-lru：优先保留最近访问过的数据
   - volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）
   - volatile-ttl ：优先淘汰即将过期的数据
   - volatile-random / allkeys-random：随机淘汰数据

6. **数据压缩后写入 Redis**

   如果你还想进一步优化 Redis 内存，你还可以在业务应用中先将数据压缩，再写入到 Redis 中（例如采用 snappy、gzip 等压缩算法）。

   当然，压缩存储的数据，客户端在读取时还需要解压缩，在这期间会消耗更多 CPU 资源，你需要根据实际情况进行权衡。

#### 如何持续发挥 Redis 的高性能？

1. **避免存储 bigkey**

   存储 bigkey 除了前面讲到的使用过多内存之外，对 Redis 性能也会有很大影响。

   由于 Redis 处理请求是单线程的，当你的应用在写入一个 bigkey 时，更多时间将消耗在「内存分配」上，这时操作延迟就会增加。同样地，删除一个 bigkey 在「释放内存」时，也会发生耗时。

   而且，当你在读取这个 bigkey 时，也会在「网络数据传输」上花费更多时间，此时后面待执行的请求就会发生排队，Redis 性能下降。

   > 如果你确实有存储 bigkey 的需求，你可以把 bigkey 拆分为多个小 key 存储。

2. **开启 lazy-free 机制**

   如果你无法避免存储 bigkey，那么我建议你开启 Redis 的 lazy-free 机制。（4.0+版本支持）

   当开启这个机制后，Redis 在删除一个 bigkey 时，释放内存的耗时操作，将会放到后台线程中去执行，这样可以在最大程度上，避免对主线程的影响。

3. **不使用复杂度过高的命令**

   Redis 是单线程模型处理请求，除了操作 bigkey 会导致后面请求发生排队之外，在执行复杂度过高的命令时，也会发生这种情况。

   因为执行复杂度过高的命令，会消耗更多的 CPU 资源，主线程中的其它请求只能等待，这时也会发生排队延迟。

   所以，你需要避免执行例如 SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE 等聚合类命令。

   对于这种聚合类操作，我建议你把它放到客户端来执行，不要让 Redis 承担太多的计算工作。

4. **执行 O(N) 命令时，关注 N 的大小**

   规避使用复杂度过高的命令，就可以高枕无忧了么？

   答案是否定的。

   当你在执行 O(N) 命令时，同样需要注意 N 的大小。

   如果一次性查询过多的数据，也会在网络传输过程中耗时过长，操作延迟变大。

   所以，对于容器类型（List/Hash/Set/ZSet），在元素数量未知的情况下，一定不要无脑执行 LRANGE key 0 -1 / HGETALL / SMEMBERS / ZRANGE key 0 -1。

   在查询数据时，你要遵循以下原则：

   1. 先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）
   2. 元素数量较少，可一次性查询全量数据
   3. 元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）

5. **关注 DEL 时间复杂度**

   你没看错，在删除一个 key 时，如果姿势不对，也有可能影响到 Redis 性能。

   删除一个 key，我们通常使用的是 DEL 命令，回想一下，你觉得 DEL 的时间复杂度是多少？

   O(1) ？其实不一定。

   当你删除的是一个 String 类型 key 时，时间复杂度确实是 O(1)。

   但当你要删除的 key 是 List/Hash/Set/ZSet 类型，它的复杂度其实为 O(N)，N 代表元素个数。

   **也就是说，删除一个 key，其元素数量越多，执行 DEL 也就越慢！**

   原因在于，删除大量元素时，需要依次回收每个元素的内存，元素越多，花费的时间也就越久！

   而且，这个过程默认是在主线程中执行的，这势必会阻塞主线程，产生性能问题。

   那删除这种元素比较多的 key，如何处理呢？

   我给你的建议是，分批删除：

   - List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成
   - Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素

6. **避免集中过期 key**

   Redis 清理过期 key 是采用定时 + 懒惰的方式来做的，而且这个过程都是在主线程中执行。

   如果你的业务存在大量 key 集中过期的情况，那么 Redis 在清理过期 key 时，也会有阻塞主线程的风险想要避免这种情况发生，你可以在设置过期时间时，增加一个随机时间，把这些 key 的过期时间打散，从而降低集中过期对主线程的影响。

7. **使用长连接操作 Redis，合理配置连接池**

   你的业务应该使用长连接操作 Redis，避免短连接。

   当使用短连接操作 Redis 时，每次都需要经过 TCP 三次握手、四次挥手，这个过程也会增加操作耗时。

   同时，你的客户端应该使用连接池的方式访问 Redis，并设置合理的参数，长时间不操作 Redis 时，需及时释放连接资源。

8. **只使用 db0**

   尽管 Redis 提供了 16 个 db，但我只建议你使用 db0。

   为什么呢？我总结了以下 3 点原因：

   1. 在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力
   2. 使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能
   3. Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高

#### 如何保证 Redis 的可靠性？

